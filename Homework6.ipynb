{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F0fOzKP-43mA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9240 entries, 0 to 9239\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   Prospect ID                                    9240 non-null   object \n",
      " 1   Lead Number                                    9240 non-null   int64  \n",
      " 2   Lead Origin                                    9240 non-null   object \n",
      " 3   Lead Source                                    9204 non-null   object \n",
      " 4   Do Not Email                                   9240 non-null   object \n",
      " 5   Do Not Call                                    9240 non-null   object \n",
      " 6   Converted                                      9240 non-null   int64  \n",
      " 7   TotalVisits                                    9103 non-null   float64\n",
      " 8   Total Time Spent on Website                    9240 non-null   int64  \n",
      " 9   Page Views Per Visit                           9103 non-null   float64\n",
      " 10  Last Activity                                  9137 non-null   object \n",
      " 11  Country                                        6779 non-null   object \n",
      " 12  Specialization                                 7802 non-null   object \n",
      " 13  How did you hear about X Education             7033 non-null   object \n",
      " 14  What is your current occupation                6550 non-null   object \n",
      " 15  What matters most to you in choosing a course  6531 non-null   object \n",
      " 16  Search                                         9240 non-null   object \n",
      " 17  Magazine                                       9240 non-null   object \n",
      " 18  Newspaper Article                              9240 non-null   object \n",
      " 19  X Education Forums                             9240 non-null   object \n",
      " 20  Newspaper                                      9240 non-null   object \n",
      " 21  Digital Advertisement                          9240 non-null   object \n",
      " 22  Through Recommendations                        9240 non-null   object \n",
      " 23  Receive More Updates About Our Courses         9240 non-null   object \n",
      " 24  Tags                                           5887 non-null   object \n",
      " 25  Lead Quality                                   4473 non-null   object \n",
      " 26  Update me on Supply Chain Content              9240 non-null   object \n",
      " 27  Get updates on DM Content                      9240 non-null   object \n",
      " 28  Lead Profile                                   6531 non-null   object \n",
      " 29  City                                           7820 non-null   object \n",
      " 30  Asymmetrique Activity Index                    5022 non-null   object \n",
      " 31  Asymmetrique Profile Index                     5022 non-null   object \n",
      " 32  Asymmetrique Activity Score                    5022 non-null   float64\n",
      " 33  Asymmetrique Profile Score                     5022 non-null   float64\n",
      " 34  I agree to pay the amount through cheque       9240 non-null   object \n",
      " 35  A free copy of Mastering The Interview         9240 non-null   object \n",
      " 36  Last Notable Activity                          9240 non-null   object \n",
      "dtypes: float64(4), int64(3), object(30)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Data description is provided below\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ogut77/DataScience/main/data/Leads.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ihog3y2T9uKN"
   },
   "outputs": [],
   "source": [
    " #There are missing values in the Lead data .\n",
    "# Replace missing variables with the mean  if variable is numeric or mode if variable is categorical.\n",
    "for col in df.columns:\n",
    "    if ((df[col].dtype == 'float64') or (df[col].dtype == 'float64')) :\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MekOuGEPHK0x",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prospect ID                                      0\n",
       "Lead Number                                      0\n",
       "Lead Origin                                      0\n",
       "Lead Source                                      0\n",
       "Do Not Email                                     0\n",
       "Do Not Call                                      0\n",
       "Converted                                        0\n",
       "TotalVisits                                      0\n",
       "Total Time Spent on Website                      0\n",
       "Page Views Per Visit                             0\n",
       "Last Activity                                    0\n",
       "Country                                          0\n",
       "Specialization                                   0\n",
       "How did you hear about X Education               0\n",
       "What is your current occupation                  0\n",
       "What matters most to you in choosing a course    0\n",
       "Search                                           0\n",
       "Magazine                                         0\n",
       "Newspaper Article                                0\n",
       "X Education Forums                               0\n",
       "Newspaper                                        0\n",
       "Digital Advertisement                            0\n",
       "Through Recommendations                          0\n",
       "Receive More Updates About Our Courses           0\n",
       "Tags                                             0\n",
       "Lead Quality                                     0\n",
       "Update me on Supply Chain Content                0\n",
       "Get updates on DM Content                        0\n",
       "Lead Profile                                     0\n",
       "City                                             0\n",
       "Asymmetrique Activity Index                      0\n",
       "Asymmetrique Profile Index                       0\n",
       "Asymmetrique Activity Score                      0\n",
       "Asymmetrique Profile Score                       0\n",
       "I agree to pay the amount through cheque         0\n",
       "A free copy of Mastering The Interview           0\n",
       "Last Notable Activity                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that there are no missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DKJ3NU0X_Gch"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "df = df.drop(columns=['Prospect ID','Lead Number'])\n",
    "y = df['Converted']\n",
    "X = df.drop(columns=['Converted'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qyiN6tHuE4Zl"
   },
   "outputs": [],
   "source": [
    "def eval(yact,ypred):\n",
    " from sklearn import metrics\n",
    " print(\"Accuracy:\",metrics.accuracy_score(yact, ypred))\n",
    " print(\"Precision:\",metrics.precision_score(yact, ypred))\n",
    " print(\"Recall:\",metrics.recall_score(yact, ypred))\n",
    " \n",
    " cnf_matrix = metrics.confusion_matrix(yact, ypred)\n",
    " import numpy as np\n",
    " import matplotlib.pyplot as plt\n",
    " import seaborn as sns\n",
    " %matplotlib inline\n",
    " class_names=[0,1] # name  of classes\n",
    " fig, ax = plt.subplots()\n",
    " tick_marks = np.arange(len(class_names))\n",
    " plt.xticks(tick_marks, class_names)\n",
    " plt.yticks(tick_marks, class_names)\n",
    " # create heatmap\n",
    " sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    " ax.xaxis.set_label_position(\"top\")\n",
    " plt.tight_layout()\n",
    " plt.title('Confusion matrix', y=1.1)\n",
    " plt.ylabel('Actual label')\n",
    " plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g2gxBq6kCdWa"
   },
   "outputs": [],
   "source": [
    "#1)With optuna method and using train data  choose best method among Random Forest\",\"XGBoost\", \"LightGBM\",\"GradientBoostingClassifier\"\n",
    "#and optimeze these method based on following parameters.\n",
    "#max_depth = trial.suggest_int(\"max_depth\", 2,X_train.shape[1])\n",
    "#max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
    "#Evaluate performance of the best method on test data using eval function defined above.\n",
    "#Note: This should be similar to what we have done in the exercises in class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x ,y =X_train, y_train\n",
    "    \n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"Random Forest\",\"XGBoost\", \"LightGBM\",\"GradientBoostingClassifier\" ])\n",
    "    if classifier_name == \"Random Forest\":\n",
    "         from sklearn.ensemble import RandomForestClassifier\n",
    "         max_depth = trial.suggest_int(\"max_depth\", 2,X_train.shape[1])\n",
    "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
    "         classifier_obj = sklearn.ensemble.RandomForestClassifier(random_state=0,  max_depth=max_depth, max_features=max_features )\n",
    "        \n",
    "         \n",
    "\n",
    "    elif classifier_name == \"XGBoost\":\n",
    "         from xgboost import XGBClassifier\n",
    "         max_depth = trial.suggest_int(\"max_depth\", 2,X_train.shape[1])\n",
    "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
    "         classifier_obj = XGBClassifier(random_state=0,  max_depth=max_depth, max_features=max_features )\n",
    "        \n",
    "         \n",
    "\n",
    "    elif classifier_name == \"LightGBM\":\n",
    "         import lightgbm as lgb\n",
    "         max_depth = trial.suggest_int(\"max_depth\", 2,X_train.shape[1])\n",
    "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
    "         classifier_obj = lgb.LGBMClassifier(random_state=0,  max_depth=max_depth, max_features=max_features )\n",
    "        \n",
    "       \n",
    "       \n",
    "    else:\n",
    "         max_depth = trial.suggest_int(\"max_depth\", 2,X_train.shape[1])\n",
    "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
    "         classifier_obj = sklearn.ensemble.GradientBoostingClassifier(random_state=0,  max_depth=max_depth, max_features=max_features )\n",
    "    \n",
    "    # Train and evaluate the classifier\n",
    "    classifier_obj.fit(x, y)\n",
    "    y_pred = classifier_obj.predict(X_test)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store the trained classifier as a user attribute of the trial if it achieves the best performance\n",
    "    if trial.should_prune() or accuracy < 0.5:\n",
    "        return float('inf')\n",
    "    trial.set_user_attr(\"best_classifier\", classifier_obj)\n",
    "    return 1 - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:27,875]\u001b[0m A new study created in memory with name: no-name-8b3b2c59-848b-438e-aa20-6acf65968bb6\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:28,655]\u001b[0m Trial 0 finished with value: 0.08585858585858586 and parameters: {'classifier': 'Random Forest', 'max_depth': 8, 'max_features': 23}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:30,663]\u001b[0m Trial 1 finished with value: 0.06565656565656564 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 10, 'max_features': 15}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:31,256]\u001b[0m Trial 2 finished with value: 0.07828282828282829 and parameters: {'classifier': 'Random Forest', 'max_depth': 31, 'max_features': 8}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:31,359]\u001b[0m Trial 3 finished with value: 0.06746031746031744 and parameters: {'classifier': 'LightGBM', 'max_depth': 6, 'max_features': 28}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:36,442]\u001b[0m Trial 4 finished with value: 0.07178932178932174 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 14, 'max_features': 17}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:41,634]\u001b[0m Trial 5 finished with value: 0.08441558441558439 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 17, 'max_features': 34}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:42,247]\u001b[0m Trial 6 finished with value: 0.08152958152958156 and parameters: {'classifier': 'Random Forest', 'max_depth': 11, 'max_features': 12}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:43,767]\u001b[0m Trial 7 finished with value: 0.07792207792207795 and parameters: {'classifier': 'Random Forest', 'max_depth': 31, 'max_features': 33}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:32:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:44,223]\u001b[0m Trial 8 finished with value: 0.06998556998557004 and parameters: {'classifier': 'XGBoost', 'max_depth': 15, 'max_features': 7}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:46,429]\u001b[0m Trial 9 finished with value: 0.06782106782106778 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 9, 'max_features': 30}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:32:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:46,899]\u001b[0m Trial 10 finished with value: 0.0670995670995671 and parameters: {'classifier': 'XGBoost', 'max_depth': 23, 'max_features': 23}. Best is trial 0 with value: 0.08585858585858586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:46,955]\u001b[0m Trial 11 finished with value: 0.09090909090909094 and parameters: {'classifier': 'LightGBM', 'max_depth': 2, 'max_features': 23}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:47,011]\u001b[0m Trial 12 finished with value: 0.09090909090909094 and parameters: {'classifier': 'LightGBM', 'max_depth': 2, 'max_features': 23}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:47,085]\u001b[0m Trial 13 finished with value: 0.07287157287157287 and parameters: {'classifier': 'LightGBM', 'max_depth': 4, 'max_features': 23}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:47,143]\u001b[0m Trial 14 finished with value: 0.09090909090909094 and parameters: {'classifier': 'LightGBM', 'max_depth': 2, 'max_features': 21}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:47,265]\u001b[0m Trial 15 finished with value: 0.06637806637806642 and parameters: {'classifier': 'LightGBM', 'max_depth': 21, 'max_features': 28}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:47,329]\u001b[0m Trial 16 finished with value: 0.07647907647907648 and parameters: {'classifier': 'LightGBM', 'max_depth': 3, 'max_features': 19}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:47,454]\u001b[0m Trial 17 finished with value: 0.06637806637806642 and parameters: {'classifier': 'LightGBM', 'max_depth': 25, 'max_features': 26}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:47,558]\u001b[0m Trial 18 finished with value: 0.06746031746031744 and parameters: {'classifier': 'LightGBM', 'max_depth': 6, 'max_features': 4}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:47,685]\u001b[0m Trial 19 finished with value: 0.06854256854256857 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 13}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:47,809]\u001b[0m Trial 20 finished with value: 0.07251082251082253 and parameters: {'classifier': 'XGBoost', 'max_depth': 2, 'max_features': 19}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:47,900]\u001b[0m Trial 21 finished with value: 0.07034632034632038 and parameters: {'classifier': 'LightGBM', 'max_depth': 5, 'max_features': 21}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:32:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:47,968]\u001b[0m Trial 22 finished with value: 0.07647907647907648 and parameters: {'classifier': 'LightGBM', 'max_depth': 3, 'max_features': 25}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:48,024]\u001b[0m Trial 23 finished with value: 0.09090909090909094 and parameters: {'classifier': 'LightGBM', 'max_depth': 2, 'max_features': 21}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:48,140]\u001b[0m Trial 24 finished with value: 0.06565656565656564 and parameters: {'classifier': 'LightGBM', 'max_depth': 7, 'max_features': 17}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:48,257]\u001b[0m Trial 25 finished with value: 0.06637806637806642 and parameters: {'classifier': 'LightGBM', 'max_depth': 8, 'max_features': 31}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:48,348]\u001b[0m Trial 26 finished with value: 0.07034632034632038 and parameters: {'classifier': 'LightGBM', 'max_depth': 5, 'max_features': 26}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:48,476]\u001b[0m Trial 27 finished with value: 0.06637806637806642 and parameters: {'classifier': 'LightGBM', 'max_depth': 27, 'max_features': 21}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[01:32:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:48,936]\u001b[0m Trial 28 finished with value: 0.06782106782106778 and parameters: {'classifier': 'XGBoost', 'max_depth': 19, 'max_features': 14}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:50,166]\u001b[0m Trial 29 finished with value: 0.07503607503607501 and parameters: {'classifier': 'Random Forest', 'max_depth': 34, 'max_features': 24}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:50,324]\u001b[0m Trial 30 finished with value: 0.06854256854256857 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 28}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:50,392]\u001b[0m Trial 31 finished with value: 0.09090909090909094 and parameters: {'classifier': 'LightGBM', 'max_depth': 2, 'max_features': 21}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:50,455]\u001b[0m Trial 32 finished with value: 0.09090909090909094 and parameters: {'classifier': 'LightGBM', 'max_depth': 2, 'max_features': 21}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:50,595]\u001b[0m Trial 33 finished with value: 0.06637806637806642 and parameters: {'classifier': 'LightGBM', 'max_depth': 8, 'max_features': 17}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n",
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:50,703]\u001b[0m Trial 34 finished with value: 0.07034632034632038 and parameters: {'classifier': 'LightGBM', 'max_depth': 5, 'max_features': 23}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:52,960]\u001b[0m Trial 35 finished with value: 0.06601731601731597 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 10, 'max_features': 19}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:53,031]\u001b[0m Trial 36 finished with value: 0.07287157287157287 and parameters: {'classifier': 'LightGBM', 'max_depth': 4, 'max_features': 11}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:32:53,855]\u001b[0m Trial 37 finished with value: 0.08982683982683981 and parameters: {'classifier': 'Random Forest', 'max_depth': 7, 'max_features': 26}. Best is trial 11 with value: 0.09090909090909094.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:54,202]\u001b[0m Trial 38 finished with value: 0.09451659451659455 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 2, 'max_features': 20}. Best is trial 38 with value: 0.09451659451659455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:59,205]\u001b[0m Trial 39 finished with value: 0.0714285714285714 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 14, 'max_features': 16}. Best is trial 38 with value: 0.09451659451659455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:32:59,947]\u001b[0m Trial 40 finished with value: 0.06637806637806642 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 6, 'max_features': 15}. Best is trial 38 with value: 0.09451659451659455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:00,303]\u001b[0m Trial 41 finished with value: 0.08658008658008653 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 2, 'max_features': 22}. Best is trial 38 with value: 0.09451659451659455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:00,751]\u001b[0m Trial 42 finished with value: 0.07792207792207795 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 3, 'max_features': 19}. Best is trial 38 with value: 0.09451659451659455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:01,575]\u001b[0m Trial 43 finished with value: 0.06998556998557004 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 5, 'max_features': 24}. Best is trial 38 with value: 0.09451659451659455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:02,044]\u001b[0m Trial 44 finished with value: 0.11544011544011545 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 20}. Best is trial 44 with value: 0.11544011544011545.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:02,636]\u001b[0m Trial 45 finished with value: 0.11544011544011545 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 28}. Best is trial 44 with value: 0.11544011544011545.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:03,751]\u001b[0m Trial 46 finished with value: 0.08405483405483405 and parameters: {'classifier': 'Random Forest', 'max_depth': 10, 'max_features': 30}. Best is trial 44 with value: 0.11544011544011545.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:04,335]\u001b[0m Trial 47 finished with value: 0.11471861471861466 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 29}. Best is trial 44 with value: 0.11544011544011545.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:04,964]\u001b[0m Trial 48 finished with value: 0.11688311688311692 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 32}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:06,131]\u001b[0m Trial 49 finished with value: 0.08585858585858586 and parameters: {'classifier': 'Random Forest', 'max_depth': 9, 'max_features': 34}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:07,093]\u001b[0m Trial 50 finished with value: 0.08982683982683981 and parameters: {'classifier': 'Random Forest', 'max_depth': 7, 'max_features': 32}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:07,781]\u001b[0m Trial 51 finished with value: 0.1028138528138528 and parameters: {'classifier': 'Random Forest', 'max_depth': 5, 'max_features': 28}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:08,345]\u001b[0m Trial 52 finished with value: 0.11544011544011545 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 28}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:09,101]\u001b[0m Trial 53 finished with value: 0.08910533910533913 and parameters: {'classifier': 'Random Forest', 'max_depth': 6, 'max_features': 28}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:09,670]\u001b[0m Trial 54 finished with value: 0.11471861471861466 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 29}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:10,254]\u001b[0m Trial 55 finished with value: 0.11399711399711399 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 30}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:11,273]\u001b[0m Trial 56 finished with value: 0.08513708513708518 and parameters: {'classifier': 'Random Forest', 'max_depth': 8, 'max_features': 32}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:11,862]\u001b[0m Trial 57 finished with value: 0.11471861471861466 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 29}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:13,381]\u001b[0m Trial 58 finished with value: 0.07756132756132761 and parameters: {'classifier': 'Random Forest', 'max_depth': 17, 'max_features': 34}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:14,469]\u001b[0m Trial 59 finished with value: 0.07900432900432897 and parameters: {'classifier': 'Random Forest', 'max_depth': 11, 'max_features': 27}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:15,094]\u001b[0m Trial 60 finished with value: 0.11688311688311692 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 32}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:15,704]\u001b[0m Trial 61 finished with value: 0.11435786435786433 and parameters: {'classifier': 'Random Forest', 'max_depth': 4, 'max_features': 31}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:16,535]\u001b[0m Trial 62 finished with value: 0.08946608946608947 and parameters: {'classifier': 'Random Forest', 'max_depth': 6, 'max_features': 32}. Best is trial 48 with value: 0.11688311688311692.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:17,058]\u001b[0m Trial 63 finished with value: 0.15873015873015872 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 33}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:17,994]\u001b[0m Trial 64 finished with value: 0.08982683982683981 and parameters: {'classifier': 'Random Forest', 'max_depth': 7, 'max_features': 33}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:18,515]\u001b[0m Trial 65 finished with value: 0.15873015873015872 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 33}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:19,038]\u001b[0m Trial 66 finished with value: 0.15873015873015872 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 33}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:19,562]\u001b[0m Trial 67 finished with value: 0.15873015873015872 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 33}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:20,085]\u001b[0m Trial 68 finished with value: 0.15873015873015872 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 33}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:20,230]\u001b[0m Trial 69 finished with value: 0.06926406926406925 and parameters: {'classifier': 'XGBoost', 'max_depth': 3, 'max_features': 33}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:33:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:33:20,778]\u001b[0m Trial 70 finished with value: 0.15873015873015872 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 33}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:21,300]\u001b[0m Trial 71 finished with value: 0.15873015873015872 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 33}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:22,181]\u001b[0m Trial 72 finished with value: 0.0905483405483406 and parameters: {'classifier': 'Random Forest', 'max_depth': 6, 'max_features': 34}. Best is trial 63 with value: 0.15873015873015872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:22,700]\u001b[0m Trial 73 finished with value: 0.1601731601731602 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 31}. Best is trial 73 with value: 0.1601731601731602.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:23,222]\u001b[0m Trial 74 finished with value: 0.1601731601731602 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 31}. Best is trial 73 with value: 0.1601731601731602.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:23,734]\u001b[0m Trial 75 finished with value: 0.1601731601731602 and parameters: {'classifier': 'Random Forest', 'max_depth': 3, 'max_features': 31}. Best is trial 73 with value: 0.1601731601731602.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:24,133]\u001b[0m Trial 76 finished with value: 0.18614718614718617 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 31}. Best is trial 76 with value: 0.18614718614718617.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:33:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:33:24,607]\u001b[0m Trial 77 finished with value: 0.06637806637806642 and parameters: {'classifier': 'XGBoost', 'max_depth': 29, 'max_features': 31}. Best is trial 76 with value: 0.18614718614718617.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:25,035]\u001b[0m Trial 78 finished with value: 0.18614718614718617 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 31}. Best is trial 76 with value: 0.18614718614718617.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:25,432]\u001b[0m Trial 79 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:25,837]\u001b[0m Trial 80 finished with value: 0.18614718614718617 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 31}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:26,234]\u001b[0m Trial 81 finished with value: 0.18614718614718617 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 31}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:26,625]\u001b[0m Trial 82 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:27,016]\u001b[0m Trial 83 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:27,407]\u001b[0m Trial 84 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:27,797]\u001b[0m Trial 85 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:28,189]\u001b[0m Trial 86 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:28,580]\u001b[0m Trial 87 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:28,700]\u001b[0m Trial 88 finished with value: 0.07251082251082253 and parameters: {'classifier': 'XGBoost', 'max_depth': 2, 'max_features': 27}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:33:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:33:29,120]\u001b[0m Trial 89 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:29,800]\u001b[0m Trial 90 finished with value: 0.10606060606060608 and parameters: {'classifier': 'Random Forest', 'max_depth': 5, 'max_features': 29}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:30,194]\u001b[0m Trial 91 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:31,603]\u001b[0m Trial 92 finished with value: 0.07539682539682535 and parameters: {'classifier': 'Random Forest', 'max_depth': 22, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:32,254]\u001b[0m Trial 93 finished with value: 0.10569985569985574 and parameters: {'classifier': 'Random Forest', 'max_depth': 5, 'max_features': 27}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:32,644]\u001b[0m Trial 94 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:33,035]\u001b[0m Trial 95 finished with value: 0.1865079365079365 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:33,653]\u001b[0m Trial 96 finished with value: 0.10209235209235212 and parameters: {'classifier': 'Random Forest', 'max_depth': 5, 'max_features': 25}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:35,050]\u001b[0m Trial 97 finished with value: 0.07539682539682535 and parameters: {'classifier': 'Random Forest', 'max_depth': 20, 'max_features': 29}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:35,421]\u001b[0m Trial 98 finished with value: 0.18542568542568538 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 27}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:36,218]\u001b[0m Trial 99 finished with value: 0.09018759018759015 and parameters: {'classifier': 'Random Forest', 'max_depth': 6, 'max_features': 30}. Best is trial 79 with value: 0.1865079365079365.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=79, state=TrialState.COMPLETE, values=[0.1865079365079365], datetime_start=datetime.datetime(2023, 4, 15, 1, 33, 25, 37950), datetime_complete=datetime.datetime(2023, 4, 15, 1, 33, 25, 420171), params={'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}, user_attrs={'best_classifier': RandomForestClassifier(max_depth=2, max_features=30, random_state=0)}, system_attrs={}, intermediate_values={}, distributions={'classifier': CategoricalDistribution(choices=('Random Forest', 'XGBoost', 'LightGBM', 'GradientBoostingClassifier')), 'max_depth': IntDistribution(high=34, log=False, low=2, step=1), 'max_features': IntDistribution(high=34, log=False, low=2, step=1)}, trial_id=79, value=None)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 30}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8134920634920635\n",
      "Precision: 0.7959413754227734\n",
      "Recall: 0.6775431861804223\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_classifier = study.best_trial.user_attrs[\"best_classifier\"]\n",
    "best_classifier.fit(X_train, y_train)\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "eval(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x, y = X_train,y_train\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"max_dept\" :trial.suggest_int(\"max_depth\", 2, X_train.shape[1]),\n",
    "        \"max_features\" : trial.suggest_int(\"max_features\", 2,X_train.shape[1]),       \n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    classifier_obj = GradientBoostingClassifier(random_state=0,max_features=2, max_depth=256)\n",
    "\n",
    "    classifier_obj.fit(x, y)\n",
    "    y_pred = classifier_obj.predict(X_test)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    if trial.should_prune() or accuracy < 0.5:\n",
    "        return float('inf')\n",
    "    trial.set_user_attr(\"best_classifier\", classifier_obj)\n",
    "    return 1 - accuracy   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 01:33:37,498]\u001b[0m A new study created in memory with name: no-name-44eb5eb1-8b10-430e-a5d0-0a71da987037\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:42,256]\u001b[0m Trial 0 finished with value: 0.09379509379509376 and parameters: {'max_depth': 30, 'max_features': 31, 'num_leaves': 125, 'feature_fraction': 0.5242091037039016, 'bagging_fraction': 0.8229856873499116, 'bagging_freq': 2, 'min_child_samples': 65}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:47,014]\u001b[0m Trial 1 finished with value: 0.09379509379509376 and parameters: {'max_depth': 20, 'max_features': 30, 'num_leaves': 5, 'feature_fraction': 0.8416850774467963, 'bagging_fraction': 0.6521136719231768, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:51,760]\u001b[0m Trial 2 finished with value: 0.09379509379509376 and parameters: {'max_depth': 2, 'max_features': 10, 'num_leaves': 194, 'feature_fraction': 0.714828575506478, 'bagging_fraction': 0.7252009721619086, 'bagging_freq': 7, 'min_child_samples': 76}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:33:56,479]\u001b[0m Trial 3 finished with value: 0.09379509379509376 and parameters: {'max_depth': 27, 'max_features': 8, 'num_leaves': 191, 'feature_fraction': 0.8844031601380353, 'bagging_fraction': 0.4539035755089019, 'bagging_freq': 4, 'min_child_samples': 75}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:01,189]\u001b[0m Trial 4 finished with value: 0.09379509379509376 and parameters: {'max_depth': 24, 'max_features': 14, 'num_leaves': 146, 'feature_fraction': 0.6732362825006604, 'bagging_fraction': 0.6173842709765447, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:05,905]\u001b[0m Trial 5 finished with value: 0.09379509379509376 and parameters: {'max_depth': 34, 'max_features': 4, 'num_leaves': 14, 'feature_fraction': 0.6388722788156871, 'bagging_fraction': 0.5646208722356165, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:10,718]\u001b[0m Trial 6 finished with value: 0.09379509379509376 and parameters: {'max_depth': 26, 'max_features': 34, 'num_leaves': 91, 'feature_fraction': 0.6562853025561501, 'bagging_fraction': 0.6276524616731332, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:15,404]\u001b[0m Trial 7 finished with value: 0.09379509379509376 and parameters: {'max_depth': 7, 'max_features': 30, 'num_leaves': 125, 'feature_fraction': 0.8621206859631283, 'bagging_fraction': 0.4384508447027051, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:20,182]\u001b[0m Trial 8 finished with value: 0.09379509379509376 and parameters: {'max_depth': 11, 'max_features': 34, 'num_leaves': 99, 'feature_fraction': 0.9879546912992477, 'bagging_fraction': 0.9906933778020156, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:24,905]\u001b[0m Trial 9 finished with value: 0.09379509379509376 and parameters: {'max_depth': 6, 'max_features': 20, 'num_leaves': 243, 'feature_fraction': 0.7588289674045868, 'bagging_fraction': 0.6642255442229716, 'bagging_freq': 1, 'min_child_samples': 84}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:29,708]\u001b[0m Trial 10 finished with value: 0.09379509379509376 and parameters: {'max_depth': 32, 'max_features': 22, 'num_leaves': 64, 'feature_fraction': 0.47561480623959423, 'bagging_fraction': 0.855828881847189, 'bagging_freq': 3, 'min_child_samples': 98}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:34,566]\u001b[0m Trial 11 finished with value: 0.09379509379509376 and parameters: {'max_depth': 17, 'max_features': 26, 'num_leaves': 10, 'feature_fraction': 0.40126288394008647, 'bagging_fraction': 0.7853153929877531, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:39,320]\u001b[0m Trial 12 finished with value: 0.09379509379509376 and parameters: {'max_depth': 18, 'max_features': 27, 'num_leaves': 54, 'feature_fraction': 0.5461062128450573, 'bagging_fraction': 0.8386192524858463, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:44,023]\u001b[0m Trial 13 finished with value: 0.09379509379509376 and parameters: {'max_depth': 21, 'max_features': 25, 'num_leaves': 174, 'feature_fraction': 0.5140920175258245, 'bagging_fraction': 0.7268994407843424, 'bagging_freq': 2, 'min_child_samples': 60}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:48,744]\u001b[0m Trial 14 finished with value: 0.09379509379509376 and parameters: {'max_depth': 14, 'max_features': 30, 'num_leaves': 43, 'feature_fraction': 0.5793193046471056, 'bagging_fraction': 0.5356863720272991, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:53,470]\u001b[0m Trial 15 finished with value: 0.09379509379509376 and parameters: {'max_depth': 30, 'max_features': 17, 'num_leaves': 252, 'feature_fraction': 0.8014407753921909, 'bagging_fraction': 0.7743649000379736, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:34:58,283]\u001b[0m Trial 16 finished with value: 0.09379509379509376 and parameters: {'max_depth': 24, 'max_features': 30, 'num_leaves': 141, 'feature_fraction': 0.632916599965412, 'bagging_fraction': 0.9171595846223207, 'bagging_freq': 5, 'min_child_samples': 67}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:35:03,100]\u001b[0m Trial 17 finished with value: 0.09379509379509376 and parameters: {'max_depth': 29, 'max_features': 24, 'num_leaves': 97, 'feature_fraction': 0.7348422789499482, 'bagging_fraction': 0.6882851925411919, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:35:07,870]\u001b[0m Trial 18 finished with value: 0.09379509379509376 and parameters: {'max_depth': 20, 'max_features': 17, 'num_leaves': 30, 'feature_fraction': 0.5817158803638908, 'bagging_fraction': 0.7958453443747664, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:35:12,759]\u001b[0m Trial 19 finished with value: 0.09379509379509376 and parameters: {'max_depth': 13, 'max_features': 30, 'num_leaves': 77, 'feature_fraction': 0.46354849524267805, 'bagging_fraction': 0.8985676733351923, 'bagging_freq': 2, 'min_child_samples': 100}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:35:17,576]\u001b[0m Trial 20 finished with value: 0.09379509379509376 and parameters: {'max_depth': 23, 'max_features': 34, 'num_leaves': 122, 'feature_fraction': 0.7950857243001054, 'bagging_fraction': 0.7399608035009679, 'bagging_freq': 5, 'min_child_samples': 66}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 01:35:22,350]\u001b[0m Trial 21 finished with value: 0.09379509379509376 and parameters: {'max_depth': 2, 'max_features': 12, 'num_leaves': 197, 'feature_fraction': 0.715067877078099, 'bagging_fraction': 0.7032233776098722, 'bagging_freq': 6, 'min_child_samples': 83}. Best is trial 0 with value: 0.09379509379509376.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "best_classifier = study.best_trial.user_attrs[\"best_classifier\"]\n",
    "best_classifier.fit(X_train, y_train)\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "eval(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTf67JtDK-dP"
   },
   "outputs": [],
   "source": [
    "#2)Using pycaret AutoML tools,make prediction on test data and evaluate performance of prediction using eval function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycaret'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m s \u001b[38;5;241m=\u001b[39m setup(data \u001b[38;5;241m=\u001b[39m result, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConverted\u001b[39m\u001b[38;5;124m'\u001b[39m, session_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[0;32m      3\u001b[0m best_model \u001b[38;5;241m=\u001b[39m compare_models()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import *\n",
    "s = setup(data = result, target = 'Converted', session_id=123)\n",
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned2 = tune_model(best_model)\n",
    "tuned_predictions = predict_model(tuned2, data=X_test)\n",
    "tuned_predictions.head()\n",
    "evalmetric(y_test,tuned_predictions['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1SvLYWmL8AM"
   },
   "outputs": [],
   "source": [
    "#3) Using Autogluon  AutoML tools,make prediction on test data and evaluate performance of prediction using eval function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autogluon.tabular'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogluon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TabularDataset, TabularPredictor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autogluon.tabular'"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(train_data)\n",
    "test_data = TabularDataset(test_data)\n",
    "\n",
    "predictor = TabularPredictor(label='Converted', problem_type='binary')\n",
    "predictor.fit(train_data)\n",
    "\n",
    "y_pred = predictor.predict(test_data)\n",
    "\n",
    "# evaluate predictions using the eval function\n",
    "y_true = test_data['Converted']\n",
    "eval(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(df_train, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(df_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
